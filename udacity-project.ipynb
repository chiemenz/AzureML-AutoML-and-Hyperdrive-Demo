{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-132734\n",
      "Azure region: southcentralus\n",
      "Subscription id: 9e65f93e-bdd8-437b-b1e8-0647cd6098f7\n",
      "Resource group: aml-quickstarts-132734\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.get(name=\"quick-starts-ws-132734\")\n",
    "#exp = Experiment(workspace=ws, name=\"udacity-project-hyper\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "#run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cpu_cluster_name = \"cpu-cluster-2\"\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing Comput Target\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_V2\", max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice, loguniform\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps1 = RandomParameterSampling(\n",
    "     {\"--C\": loguniform(-3,2), \"--max_iter\": choice(1,5,10,20,30,40,50,80,100,200,400,800,1000)}\n",
    ")\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "arguments = {\"--C\": 1.0, \"--max_iter\": 100}\n",
    "current_dir = os.getcwd()\n",
    "est = SKLearn(source_directory=current_dir, \n",
    "              entry_script=\"train.ipynb\",\n",
    "              compute_target = compute_target,\n",
    "              script_params = arguments)\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    estimator=est,\n",
    "    hyperparameter_sampling=ps1,\n",
    "    primary_metric_name=\"Accuracy\",\n",
    "    primary_metric_goal= PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=20,\n",
    "    max_concurrent_runs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "run_hyper = exp.submit(config=hyperdrive_config)\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hyper.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_run = run_hyper.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(workspace=ws, model_name=\"best-hyper-model\", model_path=\"outputs/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Regularization Strength:': 0.07304859840588435, 'Max iterations:': 50, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.8783856468955435, 'Max iterations:': 30, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.07815523037726442, 'Max iterations:': 200, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.19954366367073706, 'Max iterations:': 1000, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 1.1174328674115732, 'Max iterations:': 1, 'Accuracy': 0.887556904400607}\n",
      "{'Regularization Strength:': 0.059588646057997595, 'Max iterations:': 20, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.07931390798235143, 'Max iterations:': 40, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.3036966103888117, 'Max iterations:': 200, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 5.53221402077548, 'Max iterations:': 1, 'Accuracy': 0.887556904400607}\n",
      "{'Regularization Strength:': 1.956289473217793, 'Max iterations:': 50, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 4.777443416866079, 'Max iterations:': 800, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.4297411761960831, 'Max iterations:': 50, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 1.6294169773113119, 'Max iterations:': 80, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.937918139316466, 'Max iterations:': 1000, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 1.684823726147026, 'Max iterations:': 5, 'Accuracy': 0.9}\n",
      "{'Regularization Strength:': 1.6677973925006933, 'Max iterations:': 50, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 3.393400198522866, 'Max iterations:': 40, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 1.3024178295747109, 'Max iterations:': 40, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.07128714555671237, 'Max iterations:': 200, 'Accuracy': 0.9072837632776934}\n",
      "{'Regularization Strength:': 0.4686659825980652, 'Max iterations:': 100, 'Accuracy': 0.9072837632776934}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Revisit the best model run\n",
    "from azureml.core.run import get_run\n",
    "run = get_run(exp, \"HD_ff6daa53-4190-4c58-b79e-96b27f799cb4\")\n",
    "children = run.get_children()\n",
    "childs = [*children]\n",
    "best_score = 0\n",
    "best_child = None\n",
    "for child in childs:\n",
    "    print(child.get_metrics())\n",
    "    metrics = child.get_metrics()\n",
    "    if metrics and 'Accuracy' in metrics.keys() and metrics['Accuracy'] > best_score:\n",
    "        best_score = child.get_metrics()['Accuracy']\n",
    "        best_child = child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_auto = Experiment(workspace=ws, name=\"udacity-project-automl\")\n",
    "run_auto = exp_auto.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "ds = TabularDatasetFactory.from_delimited_files(path= \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\", header=True, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow the loading of the local module \"train.py\" doesn't work instead the clean_data method is directly initilized in the \n",
    "# udacity-project Jupyter Notebook\n",
    "import pandas as pd\n",
    "\n",
    "def clean_data(data):\n",
    "    # Dict for cleaning data\n",
    "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
    "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
    "\n",
    "    # Clean and one hot encode data\n",
    "    x_df = data.to_pandas_dataframe().dropna()\n",
    "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
    "    x_df.drop(\"job\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(jobs)\n",
    "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
    "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
    "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(contact)\n",
    "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
    "    x_df.drop(\"education\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(education)\n",
    "    x_df[\"month\"] = x_df.month.map(months)\n",
    "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
    "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
    "\n",
    "    y_df = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    return x_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)\n",
    "x['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "Counter(x['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow the registered Dataset cannot be used for AutoML \n",
    "from azureml.core import Dataset\n",
    "dataset_training = Dataset.from_pandas_dataframe(x)\n",
    "dataset_training = dataset_training.register(workspace=ws, name=\"auto-ml-training-data\", description=\"example exercise data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to use a AutoML model on a Dataset it is necessary to save it e.g. in Azureml Blob Storage and then load it from \n",
    "# there\n",
    "import os\n",
    "from azureml.core import Dataset, Datastore, Workspace\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "dataset_path = \"data/train_set.csv\"\n",
    "x.to_csv(dataset_path)\n",
    "datastore = ws.get_default_datastore()\n",
    "x.to_csv(dataset_path)\n",
    "datastore.upload(src_dir=\"data\", target_path=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.Tabular.from_delimited_files(path = [(datastore, (\"data/train_set.csv\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    compute_target = compute_target,\n",
    "    experiment_timeout_minutes=30,\n",
    "    task=\"classification\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    training_data=train_data,\n",
    "    label_column_name=\"y\",\n",
    "    n_cross_validations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "run_auto = exp_auto.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_auto.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "dir(run_auto)\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auto_run = run_auto.get_best_child()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auto_run.register_model(model_name=\"best_automl_model\", model_path=\"outputs/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(best_auto_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
